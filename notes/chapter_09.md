# Chapter 9: Markov Chain Monte Carlo

MCMC allows you to sample from the joint posterior directly without maximizing anything.

-  Removes the assumption of a multivariate normal posterior.

## 9.1 King Markov

Metropolis algorithm is a decision strategy that allows King Markov to visit his islands in proportion to their population. 

Summary from ChaptGPT:

The Metropolis algorithm is a method for generating samples from a given probability distribution. The algorithm uses a random walk process to explore the state space of the system, and a "Metropolis criterion" to decide whether to accept or reject a proposed state transition. The basic steps of the algorithm are:

Initialize the system in a randomly chosen state.

For each iteration, select a new state by proposing a random transition from the current state.

Calculate the probability of transitioning from the current state to the new state, based on the transition probabilities of the system.

Using this probability and the current temperature, decide whether to accept the new state as the current state or not, according to the Metropolis criterion, which states that the probability of accepting a move to a new state should be proportional to the ratio of the probability densities of the new and current states. If the new state is accepted, set the current state to the new state; otherwise, stay in the current state.

Repeat the above steps for a large number of iterations.

The algorithm guarantees that the sequence of states generated by the algorithm will converge to the target distribution, although it takes a long time to achieve the convergence. The temperature parameter controls the randomness of the algorithm, at high temperature the algorithm explores the entire state space and at low temperature it becomes more deterministic. The final state can be used for various applications like machine learning, statistics and physics simulation, as it samples from a target distribution

- Markov's algorithm is like an MDP where the state is the island, and the transition probability is proportional to the relative population of the next island.

## 9.2 Metropolis algorithms
Metropolis is a general algorithm. Gibbs sampling much better than metropolis.

### 9.2.1 Gibbs sampling
- Metropolis works when proposal is symmetric
- Gibbs is a variant of Metropolis-Hastings, both of which allow asymmetric proposals
- Gibbs makes adaptive proposals, where dist of proposed values adapts to current param values
- Depends on conjugate pairs of likelihoods and priors

### 9.2.2 High-dimensional Problems
- Limitations: 
  - must use conjugate priors
  - inefficient with high dimensional problems
  - *CONCENTRATION OF MEASURE*: most of the probability mass of a high-dimension distribution is always far from the mode of a distribution

## 9.3 Hamiltonian Monte Carlo
- HMC is more efficient than Metropolis and Gibbs
- Use random momentum to determine state changes according to topography

### 9.3.1
- autocorrelation is very low
- only works when state space is continuous

### 9.3.2
- HMC runs physics simulation where particle (vector of params) is given a random "flick"
- needs 1) log probabilities of data and params, 2) the gradient
- autocorrelation is not guaranteed if step size and leapfrog steps are wrong
  - called *u turn problem*
- NUTS is the no u turn sampler. 
  - infers when particle is turning around and then stops

## 9.4 Ulam
- trace and trank plots to inspect health of the Markov chain

## 9.5 Feeding your Markov chain

